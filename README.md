# ğŸ§  Machine Learning Basics â€“ End-to-End Practice Repository

Welcome to my **Machine Learning Basics** repository!  
This project is a **comprehensive collection of Jupyter Notebooks, datasets, and saved models** created during my ML learning journey.  
It covers everything from **data preprocessing and Python libraries practice** to the implementation of **core machine learning algorithms** with real datasets.

---

## ğŸ“Œ About the Project

The purpose of this repository is to **practice and understand machine learning concepts step by step**.  
I explored:
- Data preprocessing (cleaning, encoding, scaling, splitting)
- ML algorithms (Linear Regression, KNN, SVM, Decision Tree, Random Forest, ANN)
- Model saving/loading with `pickle`
- Visualization using Matplotlib
- Experiments with real-world datasets like **Iris, Insurance, Student marks, Sports, and Disease prediction**.

This repository can serve as a **learning guide for beginners** who want to see implementations of ML basics in action.

---

## ğŸ“‚ Project Structure

### ğŸ”§ **1. Data Preprocessing**
- Notebook: `DataPreprocessing.ipynb`  
- Concepts covered:
  - Handling missing values  
  - Encoding categorical variables  
  - Feature scaling (StandardScaler, MinMaxScaler)  
  - Train-test split  

---

### ğŸ“š **2. Python Libraries Practice**
- `numpyPractice.ipynb` â†’ Array creation, reshaping, indexing, mathematical operations.  
- `pandasPractice.ipynb` â†’ DataFrames, filtering, grouping, merging, handling missing values.  
- `matplotlibPractice.ipynb` â†’ Basic plotting, bar charts, line graphs, scatter plots, histograms.  

---

### ğŸ¤– **3. Machine Learning Algorithms**

#### ğŸ“ˆ Linear Regression
- Notebooks: 
  - `LinearRegression Implementation.ipynb`  
  - `Student Marks Predictor.ipynb`  
- Concepts: Predicting continuous values, regression line, Mean Squared Error.  

#### ğŸ‘¥ K-Nearest Neighbors (KNN)
- Notebooks: 
  - `KNN Implementation-1.ipynb`  
  - `KNN Implementation-2.ipynb`  
- Concepts: Distance-based classification, K-value tuning, accuracy evaluation.  

#### ğŸŒ€ Support Vector Machine (SVM)
- Notebook: `SVM Implementation-1.ipynb`  
- Concepts: Hyperplane, margin maximization, binary classification.  

#### ğŸŒ³ Decision Tree Classifier
- Notebook: `Decision Tree Classifier.ipynb`  
- Concepts: Gini index, entropy, splitting features, overfitting.  

#### ğŸŒ² Random Forest Classifier
- Notebooks:
  - `Iris dataset classification using random forest.ipynb`  
  - `Diseases Predict using Random Forest.ipynb`  
- Concepts: Ensemble learning, bagging, feature importance.  

#### ğŸ”¬ Artificial Neural Networks (ANN)
- Notebooks:
  - `ANN Implementation-1.ipynb`  
  - `ANN Implementation-2.ipynb`  
- Concepts: Layers, activation functions, forward pass, backpropagation.  

---

### ğŸ“Š **4. Datasets Included**

| Dataset | File | Usage |
|---------|------|-------|
| Iris Dataset | `iris.csv` | Flower classification |
| Student Info | `student_info.csv` | Student marks prediction |
| Insurance Dataset | `insurance.csv` | Cost prediction |
| Sports Dataset | `sports.csv` | Classification tasks |
| Disease Dataset | `dataset.csv`, `improved_disease_dataset.csv` | Disease prediction |
| Taxi Dataset | `taxi.csv` | Regression/classification practice |
| Employee Dataset | `Emp.csv` | Categorical encoding practice |

---

### ğŸ’¾ **5. Saved Models**
- `best_model.pkl` â†’ Best performing model  
- `dtc.pkl` â†’ Decision tree classifier  
- `label_encoder.pkl` â†’ Encoders for categorical features  
- `smp.pkl` â†’ Student marks predictor  

These models can be **loaded back using `pickle`** for predictions without retraining.

---

## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/ml-basics.git
cd ml-basics
